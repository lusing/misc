# 机器学习

## 绪论

## 模型评估与选择

### 经验误差与过拟合

通常我们把分类错误的样本数占样本总数的比例称为“错误率”error rate，即如果在m个样本中有a个样本分类错误，则错误率E=a/m；相应的，1-a/m称为精度accurcy，即"精度=1-错误率"。
更一般地，我们把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”error。
- 学习器训练集上的误差称为经验误差empirical error。
- 在新样本上的误差称为泛化误差generalization error。

当学习器把训练样本学得“太好”了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降。这种现象在机器学习中称为“过拟合”overfitting。与过拟合相对的是欠拟合underfitting. 

## 线性模型

## 决策树

### 基本流程

决策树学习的基本算法
输入：训练集$D={(x_1,y_1),(x_2,y_2),...,(x_m,y_m)};$
属性集：$A={a_1, a_2, ... a_d}$
过程：函数TreeGenerate(D,A)
1. 生成节点node
2. if D中样本全属于同一类别C then
3.   将node标记为C类叶节点; return
4. end if
5. if A=$\emptyset$ OR D中样本在A上取值相同 then
6.   将node标记为叶节点，其类别标记为D中样本数量最多的类; return
7. end if
8. 从A中选择最优划分属性$a_*$;
9. for $a_*$的每一个值$a_*^v$ do
10. 为node生成一个分支；令$D_v$表示D中在$a_*$上取值为$a_*^v$的样本子集；
11. if $D_v$为空 then
12. 将分支节点标记为叶节点，其类别标记为D中样本最多的类;return
13. else
14. 以TreeGenerate($D_v, A \ \{a_*\}$为分支节点
15 end if
16. end for
输出：以node为根节点的一棵决策树

显然，决策树的生成是一个递归过程。在决策树基本算法中，有三种情形会导致递归返回：
1. 当前节点包含的样本全属于同一类别，无需划分
2. 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分
3. 当前节点包含的样本集合为空，不能划分

在第2种情况下，我们把当前节点标记为叶节点，并将其类别设定为该节点所含样本最多的类别
在第3种情况下，同样把当前节点标记为叶节点，但将其类别设定为其父节点所含样本最多的类别
注意这两种情况的处理实质不同，情形2是利用当前节点的后验分布，而情形3则是把父节点的样本分布作为当前节点的先验分布

### 划分选择

由上节算法可以看出，决策树学习的关键是第8行，即如何选择最优划分属性。一般而言，随着划分过程不断进行，我们希望决策树的分支节点所包含的样本尽可能属于同一类别，即节点的纯度purity越来越高

#### 信息增益

信息熵information entropy是度量样本集合纯度的最常用的一种指标。假定当前样本集合D中第k类样本所占的比例为$p_k(k=1,2,...,|\mathcal{Y}|)$，则D的信息熵定义为:
$Ent(D)=-\sum_{k=1}^{|\mathcal{Y}|}p_k\log_2p_k$(4.1)
Ent(D)的值越小，则D的纯度越高。
假定离散属性a有V个可能的取值$\{a^1,a^2,...,a^V\}$，若使用a来对样本集D进行划分，则会产生V个分支节点，其中第v个分支节点包含了D中所有在属性a上取值为$a^v$的样本，记为$D^v$。我们可根据式4.1计算出$D^v$的信息熵，再考虑到不同的分支节点所包含的样本数不同，给分支节点赋予权重$|D^v|/|D|$，即样本数越多的分支节点的影响越大，于是可计算出用属性a对样本集D进行划分所获得的信息增益information gain:
$Gain(D,a)=Ent(D)-\sum_{v=1}^V\frac{D^v}{D}Ent(D^v)$(4.2)
一般而言，信息增益越大，则意味使用属性a来进行划分所获得的“纯度提升”越大。因此，我们可用信息增益来进行决策树的划分属性选择，即在算法第8行选择属性$a_*=\argmax_{a\in A}Gain(D,a)$. 著名的ID3决策树学习算法就是以信息增益为准则来选择划分属性。

#### 增益率

信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响，著名的C4.5决策树算法不直接使用信息增益，而是使用增益率gain ratio来选择最优划分属性。
采用与式4.2相同的符号表示，增益率定义为
$Gain\_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}$
其中
$IV(a)=-\sum_{v=1}^V\frac{|D^v|}{|D|}\log_{2}\frac{|D^v|}{|D|}$
称为属性a的固有值intrinsic value。属性a的可能取值数目越多，则固有值通常会更大。
需注意的是，增益率准则对可取值数目较少的属性有所偏好，因此，C4.5算法并不是直接选择增益率最大的候选划分属性，而是使用了一个启发式方法：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。

#### 基尼指数

CART决策树，Classification and Regression Tree使用”基尼指数”Gini index来选择划分属性，采用与式4.1相同的符号，数据集D的纯度可通知基尼值来度量：
$Gini(D)=\sum_{k=1}^{|y|}\sum_{k'\neq k}p_kp_{k'}=1-\sum_{k=1}^{|y|}p_k^2$
直观来说，Gini(D)反映了从数据集D中随机抽取两个样本，其类别标记不一致的概率。因此，Gini(D)越小，则数据集D的纯度越高。

采用与式4.2相同的符号表示，属性a的基尼指数定义为
$Gini_index(D,a)=\sum_{v=1}^{V}\frac{|D^v|}{|D|}Gini(D^v)$
于是，我们在候选属性集合A中，选择那个使划分后基尼指数最小的属性作为最优划分属性，即$a_*=argmin_{a\in{A}}Gini\_index(D,a)$

#### 剪枝处理

剪枝pruning是决策树学习算法对付“过拟合”的主要手段。在决策树学习中，为了尽可能正确分类训练样本，节点划分过程将不断重复，有时会造成决策树分支过多，这时就可能因训练样本学得“太好”了，以致于把训练集自身的一些特点当作所有数据都具有的一般性质而导致过拟合。因此，可通过主动去掉一些分支来降低过拟合的风险。
决策树剪枝的基本策略有“预剪枝”(prepruning)和“后剪枝”(postpruning).
预剪枝是指在决策树生成过程中，对每个节点在划分前先进行估计，若当前节点的划分不能带来决策树泛化性能的提升，则停止划分并将当前节点标记为叶节点；
后剪枝则是先从训练集生成一棵完整的决策树，然后自底同上地对非叶节点进行考察，若将该节点对应的子树替换为叶节点能带来决策树泛化性能提升，则将该子树替换为叶节点。

### 连续与缺失值

#### 连续值处理

现实学习任务中党会遇到连续属性，有必要讨论如何在决策树学习中使用连续属性。
由于连续属性的可取值数目不再有限，因此，不能直接根据连续属性的可取值来对节点进行划分。此时，连续属性离散化技术可派上用场。最简单的策略是采用二分法bi-partition对连续属性进行处理，这正是C4.5决策树算法中采用的机制。

#### 缺失值处理

现实任务中常会遇到不完整样本，即样本的某些属性缺失。尤其是在属性数目较多的情况下，往往会有大量样本出现缺失值。如果简单地放弃不完整样本，仅使用无缺失值的样本来进行学习，显然是对数据信息极大的浪费。

### 多变量决策树

若我们把每个属性视为坐标空间中的一个坐标轴，则d个属性描述的样本就对应了d维空间的一个数据点，对样本分类则意味着在这个坐标空间中寻找不同类样本之间的分类边界。决策树所形成的分类边界有一个明显的特点：轴平行(axis-parallel)，即它的分类边界由若干个与坐标轴平行的分段组成。

## 神经网络

## 支持向量机

## 贝叶斯分类器

### 贝叶斯决策论
Bayesian decision theory是概率框架下实施决策的基本方法。对分类任务来说,在所有相关概率都已知的理想情形下,贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别标记. 下面我们以多分类任务为例来解释其基本原理.
假设有N种可能的类别标记,即$\mathcal Y=\{c_1,c_2,...,c_N\}$,$\lambda_{ij}$是将一个真实标记为$c_j$的样本误分类$c_i$所产生的期望损失expected loss,即在样本x上的"条件风险"conditional risk
$R(c_i | x)=\sum_{j=1}^N\lambda_{ij}P(c_j|x)$ (7.1)
我们的任条是寻找一个判定标准$h:\mathcal X\mapsto\mathcal Y$以最小化总体风险:
$R(h)=\mathbb E_x[R(h(x)|x]$ (7.2)
显然，对每个样本x，若h能早小化条件风险R(h(x)|x)，则总体风险R(h)也将被最小化．这就产生了贝叶斯判定准则Bayes decision rule: 为最小化总体风险，只需在每个样本上选择那个能使条件风险R(c|x)最小的类别标记，即
$h^*(x)=argmin_{c\in\mathcal Y}R(c|x)$
此时，$h^*$称为贝叶斯最优分类器Bayes optimal classifier，与之对应的总体$R(h^*)$称为贝叶斯风险Bayes risk. $1-R(h^*)$反映了分类器所能达到的最好性能，即通过机器学习所能产生的模型精度的理论上限。
具体来说，若目标是最小化分类错误率，则误判损失$\lambda_{ij}$可写为：
$\lambda_{ij}=\left \{
\begin{aligned}
{0, if\quad i=j} \\
{1, otherwise} 
\end{aligned}
\right.$
此时条件风险$R(c|x)=1-P(c|x)$ (7.5)

于是，最小化分类错误率的贝叶斯最优分类器为
$h^*(x)=argmax_{c\in\mathcal Y}P(c|x)$ (7.6)
即对每个样本x, 选择能使后验概纺P(c|x)最大的类别标记
不能看出，欲使用贝叶斯判定准则来最小化决策风险，首先要获得后验概率P(c|x)。然而，在现实任务中这通常难以直接获得。从这个角度看，机器学习所要实现的是基于有限的训练样本集尽可能准确地估计出后验概率P(c|x)。大体来说，主要有两种策略：
- 给定x，可通过直接建模P(c|x)来预测c，这样得到的是判别式模型discriminative models; 决策树、BP神经网络、支持向量机等都属于判别式模型
- 也可先对联合概率分布P(x,c)建模，然后再由此获得P(c|x)，这样得到的是生成式模型generative models.
对于生成式模型来说，必然考虑
$P(c|x) =\frac{P(x,c)}{P(x)}$ (7.7)
基于贝叶斯定理，P(c|x)可写为
$P(x|c) = \frac{P(c)P(x|c)}{P(x)}$
其中，
- P(c)是类“先验”prior概率；
- P(x|c)是样本x相对于类标记c的类条件概率class-conditional probability，或称为似然likelihood；
- P(x)是用于归一化的证据因子evidence. 对给定样本x，证据因子P(x)与类标记无关，因此估计P(c|x)的问题就转化为如何基于训练数据D来估计先验P(c)和似然P(x|c)
类先验概率P(c)表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，P(c)可通过各类样本出现的频率来进行估计
对类条件概率P(x|c)来说，由于它涉及关于x所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。例如，假设样本的d个属性都是二值的，则样本空间将有$2^d$种可能的取值，在现实应用中，这个值往往远大于训练样本数m。也就是说，很多样本取值在训练集中根本没有出现，直接使用频率来估计P(x|c)显然不可行，因为“未被观测到”与“出现概率为0”通常是不同的。

### 极大似然估计
估计类条件概率的一种常用策略是先假定其具有某种确定的概率的分布形式，再基于训练样本对概率分布的参数进行估计。具体地，记关于类别c的类条件概率为P(x|c)，假设P(x|c)具有确定的形式并且被参数向量$\theta_c$唯一确定，则我们的任务就是利用训练集D估计参数$\theta_c$.
事实上，概率模型的训练过程就是参数估计parameter estimation过程。对于参数估计，统计学界的两个学派分别提供了不同的解决方案：频率主义学派Frequentist认为参数虽然未知，但却是客观存在的固定值，因此，可通过优化似然函数等准则来确实参数值；贝叶斯学派Bayesian则认为参数是未观察到的随机变量，其本身也可有分布。因此，可假定参数服从一个先验分布，然后基于观测到的数据来计算参数的后验分布。
本节介绍源自频率主义学派的极大似然估计Maximum Likelihood Estimation MLE，这是根据数据采样来估计概率分布参数的经典方法。
令$D_c$表示训练集D中第c类样本组成的集合，假设这些样本是独立同分布的，则参数$\theta_c$对于数据集$D_c$的似然是：
$P(D_c|\theta_c)=\prod_{x\in D_c}P(x|\theta_c)$ (7.9)
对$\theta_c$进行极大似然估计，就是支寻找能最大化似然$P(D_c|\theta_c)$的参数值$\hat\theta_c$。直观上看，极大似然估计是试图在$\theta_c$所有可能的取值中，找到一个能使数据出现的“可能性”最大的值。
式(7.9)中的连乘操作易造成下溢，通常使用对数似然log-likelihood:
$LL(\theta_c)=\log P(D_c|\theta_c)=\sum_{x\in D_c}\log P(x|\theta_c)$ (7.10)
此时参数$\theta_c$的极大似然估计$\hat\theta_c$为
$\hat\theta_c=argmax_{\theta_c}LL(\theta_c)$

### 朴素贝叶斯分类器

假设属性独立

### 半朴素贝叶斯分类器

假设属性只依赖另一个属性：独依赖

### 贝叶斯网

贝叶斯网Bayesian network亦称belief network，它借助有向无环图DAG来刻画属性之间的依赖关系，并使用条件概率表Conditional Probability Table-CPT来描述属性的联合概率分布。

### EM算法

EM - Expectation-Maximization算法是常用的估计参数隐变量的利器，它是一种迭代式的方法，其基本思想是：若参数$\Theta$已知，则可根据训练数据推断中最优隐变量Z的值(E步)；反之，若Z的值已知，则可方便地对参数$\Theta$做合肥市大似然估计(M步)

## 集成学习

### 个体与集成
ensemble learning集成学习通过构建并结合多个学习器来实成学习任务,有时也被称为多分类器系统multi-classifier system,基于委员会的学习committee-based learning等.

### Boosting

### Bagging与随机森林

### 结合策略

### 多样性

## 第九章 聚类

### 9.1 聚类任务

在“无监督学习”(unsupervised learning)中，训练样本的标记信息是未知的，目标是通过对无标记训练的样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础。此类学习任务中研究最多、庆用最广的是“聚类”(clustering). 

聚类试图将数据集中的样本划分为若干个通常是不相交的子集，每个子集称为一个“簇”(cluster). 通过这样的划分，每个簇可能对应于一些潜在的概念；需说明的是，这些概念对聚类算法而言事先是未知的，聚类过程仅能自动形成簇结构，簇对应的概念语义需由使用者来把握和命名。

形式化地说，假定样本集$D={x_1,x_2,...,x_m}$包含m个无标记样本，每个样本$x_i$是一个n维特征向量，即$x_i=(x_{i1},x_{i2},...,x_{in})$，则聚类算法将D划分为k个不相交的簇$C_l={l=1,2,...,k}$，其中$C_{l'}\cap_{l'\neq l}C_l=\empty$.且$D=\cup_{l=1}^kC_l$. 相应地，我们用$\lambda_i\in\{1,2,...,k\}$表示样本$x_i$的簇标记(cluster label)，即$x_i\in C_{\lambda_i}$. 于是，聚类的结果可用一个簇划分向量$\lambda=(\lambda_1,\lambda_2,...,\lambda_m)$来描述。

聚类既能作为一个单独过程，用于找寻数据内在的分布结构，也可作为分类等其他学习任务的前驱过程。例如，在一些商业应用中需对新用户的类型进行判别，但定义“用户类型”对商家来说却可能不太容易，此时往往可先对用户数据进行聚类，根据聚类结果将每个簇定义为一个类型，然后再基于这些类训练分类模型，用于判别新用户的类型。

基于不同的学习策略，人们设计出多种类型的聚类算法。 本章后半部分将对不同类型的代表性算法进行介绍，但在此之前，我们先讨论聚类算法涉及的两个基本问题-性能度量和距离计算。

### 9.2 性能度量

聚类性能度量亦称为“有效性指标”(validity index)。与监督学习中的性能度量类似，对聚类结果，我们需通过某种性能度量来评估其好坏；另一方面，若明确了最终将要使用的性能度量，则可直接将其作为聚类过程的优化目标，从而更好地得到符合要求的聚类结果。

聚类是将样本集D划分为若干互不相交的子集，即样本簇，那么，什么样的聚类结果比较好呢？直观上看，我们希望“物以类聚”，即同一簇的样本尽可能彼此相似，不同簇的样本尽可能不同。换言之，聚类结果的“簇内相似度(intra-cluster similarity)”应高，“簇间相似度(inter-cluster similarity)”应低.

聚类性能度量大致有两类。一类是将聚类结果与某个“参考模型”(reference model)进行比较，称为“外部指标”(external index)；另一类是直接考察聚类结果而不利用任何参考模型，称为“内部指标”(internal index).

对数据集$D={x_1,x_2,...,x_m}$,假定通过聚类给出了簇划分$C={C_1,C_2,...,C_k}$,参考模型给出的簇划分为$C^*={C_1^*,C_2^*,...,C_s^*}$。相应地，令$\lambda$与$\lambda^*$分别表示样本与参考模型的簇标记向量。我们将样本两两配对考虑，定义

$a=|SS|,SS=\{(x_i,x_j)|\lambda_i=\lambda_j,\lambda_i^*=\lambda_j^*,i<j\}$ (9.1)

$b=|SD|,SD=\{(x_i,x_j)|\lambda_i=\lambda_j,\lambda_i^*\neq\lambda_j^*,i<j\}$ (9.2)

$c=|DS|,DS=\{(x_i,x_j)|\lambda_i\neq\lambda_j,\lambda_i^*=\lambda_j^*,i<j\}$ (9.3)

$d=|DD|,DD=\{(x_i,x_j)|\lambda_i\neq\lambda_j,\lambda_i^*\neq\lambda_j^*,i<j\}$ (9.4)

其中集合SS包含了在C中隶属于相同簇且在C*中也隶属于相同簇的样本对，集合SD包含了在C中隶属于相同簇但在C*中隶属于不同簇的样本对，集合DS包含了在C中隶属于不同簇但在C*中隶属于相同簇的样本对，集合DD包含了在C中隶属于不同簇且在C*中也隶属于不同簇的样本对。由于每个样本对$(x_i,x_j)$只能属于上述四个集合中的一个，因此有$a+b+c+d=\frac{m(m-1)}{2}$成立。

基于式(9.1)-(9.4)，可导出下面这些常用的聚类性能度量外部指标：

Jaccard系数(Jaccard coefficient, JC):

$JC=\frac{a}{a+b+c}$ (9.5)

FM指数(Fowlkes and Mallows index, FMI):

$FMI=\sqrt{\frac{a}{a+b}\cdot\frac{a}{a+c}}$ (9.6)

Rand指数(Rand index, RI):

$RI=\frac{2(a+d)}{m(m-1)}$ (9.7)

显然，上述性能质量指标的结果值均在[0,1]区间内，值越大越好。

考虑聚类结果的簇划分$C={C_1,C_2,...,C_k}$，定义

$avg(C)=\frac{2}{|C|(|C|-1)}\sum_{1\leq i<j\leq |C|}dist(x_i,x_j)$ (9.8)

${diam}(C)=\max_{1\leq i\leq j\leq|C|} dist(x_i,x_j)$ (9.9)

$d_{\min}(C_i,C_j)=\min_{x_i\in C_i,x_j\in C_j}dist(x_i,x_j)$ (9.10)

$d_{cen}(C_i,C_j)=dist(\mu_i,\mu_j)$ (9.11)

其中，$dist(x_i,x_j)$是样本$x_i$与$x_j$之间的距离，$\mu$代表簇$C$的中心点，即$\mu=\frac{1}{|C|}\sum_{1\leq i\leq|C|}x_i$。显然，$avg(C)$是簇$C$中样本两两之间距离的平均值，${diam}(C)$是簇$C$中样本之间距离的最大值，$d_{\min}(C_i,C_j)$是簇$C_i$中的样本与簇$C_j$中的样本之间距离的最小值，$d_{cen}(C_i,C_j)$是簇$C_i$的中心点与簇$C_j$的中心点之间的距离。

基于式(9.8)-(9.11)，可导出下面这些常用的聚类性能度量内部指标：

DB指数(Davies-Bouldin index, DBI):

$DBI=\frac{1}{k}\sum_{i=1}^k\max_{j\neq i}\left(\frac{avg(C_i)+avg(C_j)}{d_{cen}(\mu_i,\mu_j)}\right)$ (9.12)

Dunn指数(Dunn index, DI):

$DI=\min_{1\leq i\leq k}\left(\min_{j\neq i}\left(\frac{d_{\min}(C_i,C_j)}{\max_{1\leq l\leq k}{diam(C_l)}}\right)\right)$ (9.13)

显然，DBI的值越小越好，而DI则相反，值越大越好。

### 9.3 距离计算

对函数$dist(x_i,x_j)$,若它是一个“距离度量”(distance metric)，则需满足一些基本性质：

1. 非负性：$dist(x_i,x_j)\geq 0$，且$dist(x_i,x_j)=0$当且仅当$x_i=x_j$；

2. 同一性：$dist(x_i,x_j)=dist(x_j,x_i)$；

3. 对称性：$dist(x_i,x_j）=dist(x_j,x_i)$；

4. 直递性：$dist(x_i,x_j)\leq dist(x_i,x_k)+dist(x_k,x_j)$。

### 9.4 原型聚类

原型聚类亦称“基于原型的聚类(prototype-based clustering)"，此类算法假设聚类结构能通过一组原型刻画，在现实聚类任务中极为常用。通常情形下，算法先对原型进行初始化，然后对原型进行迭代更新求解。采用不同的原型表示、不同的求解方式，将产生不同的算法。下面介绍几种著名的原型聚类算法。

#### 9.4.1 k均值算法

### 密度聚类

### 层次聚类

## 降维与度量学习

### k近邻学习

### 低维嵌入

### 主成分分析

### 核化线性降维

### 流形学习

manifold learning是一类借鉴了拓扑流形概念的降维方法

#### 等度量映射

#### 局部线性嵌入

### 度量学习

## 特征选择与稀疏学习

### 子集搜索与评价

### 过滤式选择

### 包裹式选择

### 嵌入式选择与L1正则化

### 稀疏表示与字典学习

### 压缩感知

## 计算学习理论

### 基础知识

顾名思义，计算学习理论(computational learning theory)研究的是关于通过“计算”来进行“学习”的理论，即关于机器学习的理论基础，其目的是分析学习任务的困难本质，为学习算法提供理论保证，并根据分析结果指导算法设计。
给定样例集$D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\},x_i\in\mathcal{X}$,本章主要讨论二分类问题,若无特别说明,$y_i\in\mathcal Y=\{-1,+1\}$. 假设$\mathcal{X}$中的所有样本服从一个隐含未知的分布$\mathcal D$, D中所有样本都是独立地从这个分布上采样而得,即独立同分布样本i.i.d independent and identical distributed
令h为从$\mathcal X$到$\mathcal Y$的一个映射,其泛化为
$E(h;\mathcal D)=P_{x\in\mathcal D}(h(x)\neq y)$ (12.1)

h在D上的经验误差为
$\hat E(h;D)= \frac{1}{m}\sum_{i=1}m\mathbb{I}(h(x_i)\neq y_i)$

由于D是$\mathcal D$的独立同分布采样,因此h的经验误差的期望等于其泛化误差.在上下文明确时,

### PAC学习

### 有限假设空间

### VC维

### Rademacher复杂度

### 稳定性

## 半监督学习

### 未标记样本

### 生成式方法

### 半监督SVM

### 图半监督学习

### 基于分歧的方法

### 半监督聚类

## 概率图模型

### 隐马尔可夫模型

概率模型(probabilistic model)提供了一种描述框架，将学习任务归结于计算变量的概率分布，在概率模型中，利用已知变量推测未知变量的条件分布称为“推断”(inference)，其核心是如何基于可观测变量推测出未知变量的条件分布。具体来说，假定所关心的变量集合为Y，可观测变量集合为O，其他变量的集合为R。“生成式”generative模型考虑联合分布P(Y,R,O)，“判别式”discriminative模型考虑条件分布P(Y,R|O)。给定一组观测变量值，推理就是要由P(Y,R,O)或P(Y,R|O)得到条件概率分布P(Y|O)。

直接利用概率求和规则消去显然不可行，因为复杂度太高。另一方面，属性变量之间往往存在复杂的联系。

概率图模型(probabilistic graphical model)是一类用图来表达变量相关关系的概率模型。它以图为表示工具，最常见的是用一个结点表示一个或一组随机变量，结点之间的边表示变量间的概率相关关系，即“变量关系图”。根据边的性质不同，概率图模型大致分为两类：第一类是使用有向无环图表示变量间的依赖关系，称为有向图模型或者贝叶斯网Bayesian network;第二类是使用无向图表示变量间的相关关系，称为无向图模型或马尔可夫网Markov network。

隐马尔可夫模型Hidden Markov Model简称HMM是结构最简单的动态贝叶斯网Dynamic Bayesian network，这是一种著名的有向图模型，主要用于时序建模，在语音识别、自然语言处理等领域有广泛应用。

隐马尔可夫模型中的变量可分为两组：
- 第一组是状态变量$\{y_1, y_2, ... ,y_n\}$，其中$y_i\in\mathcal{Y}$表示第i时刻的系统状态。通常假定状态变量是隐藏的、不可被观测的，因此状态变量亦称为隐变量hidden variable。
- 第二组是观测变量$\{x_1,x_2,...,x_n\}$，其中$x_i\in\mathcal{X}$表示第i时刻的观测值。在隐马尔可夫模型中，系统通常在多个状态$\{s_1,s_2,...,s_n\}$之间转换，因此状态变量$y_i$的取值范围$\mathcal{Y}$(称为状态空间)通常是有N个可能取值的离散空间。

### 马尔可夫随机场

### 条件随机场

### 学习与推断

### 近似推断

### 话题模型

## 规则学习

### 基本概念

机器学习中的“规则”rule通常是指语义明确、能描述数据分布所隐含的客观规律或领域概念、可写成“若...则”形式的逻辑规则。“规则学习”rule learning是从训练数据中学习出一组用于对未见示例进行判别的规则。

形式化地看，一条规则形如：
$\oplus \gets f_1 \land f_2 \land ... \land f_L$
其中逻辑蕴含符号"$\gets$"右边部分称为“规则体”body,表示该条规则的前提，左边部分称为“规则头”head，表示该条规则的结果。规则体是由逻辑文字literal $f_k$组成的合取式conjunction，其中合取符号$\gets$用来表示“并且”。每个文字$f_k$都是对示例属性进行检验的布尔表达式。L是规则体中逻辑文字的个数，称为规则的长度。规则头的$\oplus$同样是逻辑文字，一般用来表示规则所判定的目标类别或概念，例如“好瓜”。这样的逻辑规则也被称为“if-then规则”。
与神经网络、支持向量机这样的“黑箱模型”相比，规则学习具有更好的可解释性，能使用户更直观地对判别过程有所了解。另一方面，数理逻辑具有极强的表达能力，绝大多数人类知识都能通过数理逻辑进行简洁的刻画和表达。因此，规则学习能更自然地在学习过程中引入领域知识。此外，逻辑规则的抽象描述能力在处理一些高度复杂的AI任务时具有显著的优势。
规则集合中的每条规则都可看作一个子模型，规则集合是这些子模型的一个集成。当同一个示例被判别结果不同的多条规则覆盖时，称发生了冲突conflict，解决冲突的办法称为冲突消解conflict resolution。常用的冲突消解策略有投票法、排序法、元规则法等。投票法是将判别相同的规则数最多的结果作为最终结果。排序法是在规则集合上定义一个顺序，在发生冲突时使用排序最前的规则；相应的规则学习过程称为“带序规则”ordered rule学习或“优先级规则”priority rule学习。元规则法是根据领域知识事先设定一些元规则meta-rule，即关于规则的规则，例如“发生冲突时使用长度最小的规则”，然后根据元规则的指导来使用规则集。
规则学习算法通常会设置一条“默认规则”default rule，由它来处理规则集合未覆盖的样本。
从形式语言表达能力而言，规则可分为两类：命题规则propositional rule和一阶规则first-order rule。命题规则是由原子命题propositional atom和逻辑连接词与$\land$,或$\lor$,非$\not$和蕴含$\gets$构成的简单陈述句。一阶规则的基本成分是能描述事物的属性或关系的“原子公式”atom formula。
显然，从形式语言系统的角度来看，命题规则是一阶规则的特例，因此一阶逻辑的学习比命题规则要复杂得多。

### 序贯覆盖 sequential covering

规则学习的目标是产生一个能覆盖尽可能多的样例的规则集，最直接的做法是序贯覆盖sequential covering，即逐条归纳：在训练集上每学到一条规则，就将该规则覆盖的训练样例去除，然后以剩下的训练样例组成训练集重复上述过程。由于每次只处理一部分数据，因此也被称为分治策略separte-and-conquer.
对规则学习目标$oplus$，产生一条规则就是寻找最优的一组逻辑文字来构成规则体，这是一个搜索问题。

这种基于穷尽搜索的做法在属性和候选值较多时会由于组合爆炸而不可行。现在任务中一般有两种策略来产生规则：第一种是“自顶向下”top-down，即从比较一般的规则开始，逐渐添加新文字以缩小规则覆盖范围，直到满足条件为止；亦称为“生成-测试”generate-then-test法，是规则逐渐特化specialization的过程。第二种策略是“自底向上”bottom-up，即从比较特殊的规则开始，逐渐删除文字以扩大规则覆盖范围，直到满足条件为止；亦称为“数据驱动”data-driven法，是规则逐渐泛化generalization的过程。第一种策略是覆盖范围从大往小搜索规则，第二种策略则相反；前者通常更容易产生泛化性能较好的规则，而后者则更适合于训练样本较少的情形，此外，前者对噪声的鲁棒性比后者要强得多。因此，在命题规则学习中通常使用第一种策略，而第二种策略在一阶规则学习这类假设这间非常复杂的任务上使用较多。

### 剪枝优化

规则生成本质上是一个贪心搜索过程，需有一定的机制来缓解过拟合的风险，最常见的做法是剪枝pruning。与决策树相似，剪枝可发生在规则生长过程中，即“预剪枝”，也可发生在规则产生后，即“后剪枝”。通常是基于某种能度量指标来评估增、删逻辑文字前后的规则性能，或增删规则前后的规则集性能，从而判断是否要进行剪枝。
剪枝还可借助统计显著性检验来进行。例如CN2算法在预剪枝时，假设用规则集进行预测必须显著优于直接基于训练样例集后验概率分布进行预测。为便于计算，CN2使用了似然率统计量LRS Likelihood Ratio Statistics。令$m_+$,$m_-$分别表示训练样例集中的正、反例数目，$\hat{m}_+$,$\hat{m}_-$分别表示规则（集）覆盖的正反、例数目，则有：
$LRS=2 \cdot(\hat{m}_+\log_2\frac{\frac{\hat{m_+}}{\hat{m}_++\hat{m}_-}}{\frac{m_+}{m_++m_-}} + \hat{m}_-\log_2\frac{\frac{\hat{m_-}}{\hat{m}_++\hat{m}_-}}{\frac{m_-}{m_++m_-}}) $
这实际上是一种信息量指标，衡量了规则集覆盖样例的分布与训练集经验分布的差别：LRS越大，说明采用规则集进行预测与直接使用训练集正、反例比率进行猜测的差别越大；LRS越小，说明规则集的效果越可能仅是偶然现象。在数据量比较大的现实任务中，通常设置为在LRS很大时(例如0.99)时CN2算法才停止规则集生长。
后剪枝最常用的策略是“减错剪枝”REP Reduced Error Pruning。其基本算法是：将样例集划分为训练集和验证集，从训练集上学得规则集$\mathcal{R}$后进行多轮剪枝，在每一轮穷举所有可能的剪枝操作，包括删除规则中的某个文字、删除规则结尾文字、删除规则尾部多个文字、删除整条规则，然后用验证集对剪枝产生的所有候选规则集进行评估，保留最好的那个规则集进行下一轮剪枝，如此继续，直到无法通过剪枝提高验证集上的性能为止。
REP剪枝通常很有效，但其复杂度是$O(m^4)$，m为训练样例数目。IREP(Incremental REP)将复杂度降到$O(m\log^2m)$，其做法是：在生成每条规则前，先将当前样例划分为训练集和验证集，在训练集上生成一条规则r，立即在验证集上对其进行REP剪枝，得到规则r';将r'覆盖的样例去除，在更新后的样例集上重复上述过程。显然，REP是针对规则集进行剪枝，而IREP仅对单条规则进行剪枝，因此后者比前者高效。
若将剪枝机制与其他一些后处理手段结合起来对规则集进行优化，则往往能获得更好的效果。以著名的规则学习算法RIPPER为例，其泛化性能超过很多决策树算法，而且学习速度也比大多数决策树算法更快，奥妙就在于将剪枝与后处理优化相结合。
RIPPER算法如下：

```pascal
输入：训练样例集D；重复次数k.
过程：
R:=IREP*(D);
i:=0;
repeat
  R' = PostOpt(R);
  Di= NotCovered(R',D);
  Ri=IREP*(Di);
  R = R' \/ Ri;
  i := i+1;
until i=k
输出：规则集R
```
它先使用IREP*剪枝机制生成规则集$\mathcal{R}$. IREP*是IREP的改进，主要是以$\frac{\hat{m}+(m_--\hat{m}_-)}{m_++m_-}$取代了IREP使用的准确率作为规则性能度量指标，在剪枝时删除规则尾部的多个文字，并在最终得到规则集之后再进行一次IREP. RIPPER中的后处理机制是为了在剪枝的基础上进一步提升性能。 对$\mathcal{R}$中的每条规则ri，RIPPER为它产生两个变体：
- $r_i'$: 基于ri覆盖的样例，用IREP*重新生成一条规则ri'，该规则称为替换规则replacement rule.
- $r_i''$: 对ri增加文字进行特化，然后再用IREP*剪枝生成一条规则ri''，该规则称为修订规则revised rule.
接下来，把ri'和ri''分别与R中除ri之外的规则放在一起，组成规则集R'和R''，将它们与R一起进行比较，选择最优的规则集保留下来。这就是算法中PostOpt所做的操作。
为什么RIPPER的优化策略会有效呢？原因很简单：最初生成R的时候，规则是按序生成的，每条规则都没有对其后产生的规则加以考虑，这样的贪心算法本质常导致算法陷入局部最优；RIPPER的后处理优化过程将R中的所有规则放在一起重新加以优化，恰是通过全局的考虑来缓解贪心算法的局部性，从而往往能得到更好的效果。

### 一阶规则学习

受限于命题逻辑表达能力，命题规则学习难以处理对象之间的关系relation，而关系信息在很多任务中非常重要。
一阶规则学习能容易地引入领域知识，这是它相对于命题规则学习的另一大优势。在现有属性的基础上基于领域知识构造出新属性，或基于领域知识设计某种函数机制（例如正则化）来对假设空间加以约束。
FOIL(First-Order Inductive Learner)是著名的一阶规则学习算法，它遵循序贯覆盖框架且采用自顶向下的规则归纳策略，与命题规则学习过程很相似。但由于逻辑变量的存在，在FOIL在规则生成时需考虑不同的变量组合。
FOIL使用“FOIL增益”FOIL gain来选择文字：
$F_{Gain}=\hat{m}_+\times(\log_2\frac{\hat{m}_+}{\hat{m}_++\hat{m}_-}-\log_2\frac{m_+}{m_++m_-})$
其中，$\hat{m}_+$,$\hat{m}_-$分别为增加候选文字后新规则覆盖的正、反例数；m+,m-为原规则覆盖的正、反例数。FOIL增益与决策树使用的信息增益不同，它仅考虑正例的信息量，并且又新规则覆盖的正例数作为权重。这是由于关系数据中正例数往往远少于反例数，因此通常对正例应赋予更多的关注。
若允许将目标谓词作为候选文字加入规则体，则FOIL能学出递归规则；若允许将否定形式文字$\lnot F$加入候选，则往往能得到更简洁的规则集。
FOIL可大致看作命题规则学习与归纳程序设计之间的过渡，其自顶向下的规则生成过程不能支持函数和逻辑表达式嵌套，因此规则表达能力仍有不足；但它是把命题规则学习过程通过变量替换等操作直接转化为一阶规则学习，因此比一般归纳逻辑程序设计技术更高效。

### 归纳逻辑程序设计

归纳逻辑程序设计Inductive Logic Programming, ILP在一阶规则学习中引入了函数和逻辑表达式嵌套。一方面，这使得机器学习系统具备了更为强大的表达能力；另一方面，ILP可看作用机器学习技术来解决基于背景知识的逻辑程序logic program归纳，其学得的规则可被prolog等逻辑程序设计语言直接使用。
然而，函数和逻辑表达式嵌套的引入也带来了计算上的巨大挑战。例如，给定一元谓词P和一元函数f，它们能组成的文字有P(X), P(f(X)), P(f(f(X)))等无穷多个，这就使得规则学习过程中可能的候选原子公式有无穷多个。若仍采用命题逻辑规则或FOIL学习那样自顶向下的规则生成过程，则在增加规则长度时将因无法列举所有候选文字而失败。实际困难还不止这些，例如计算FOIL增益需对规则覆盖的全部正反例计数，而在引入函数和逻辑表达式嵌套之后这也变得不可行。

#### 最小一般泛化

#### 逆归结

## 强化学习

### K-摇臂赌博机

### 有模型学习

### 免模型学习

#### 蒙特卡罗强化学习

#### 时序差分学习

Sarsa

Q-learning

### 值函数近似

### 模仿学习 - imitation learning

#### 直接模仿学习

#### 逆强化学习

## 附录

### 概率分布

期望$\mathbb{E}$
方差var
协方差cov

#### 均匀分布

均匀分布uniform distribution是关于定义在区间[a,b](a<b)上连续变量的简单概率分布。
其概率密度为：$p(x|a,b) = U(x|a,b) = \frac{1}{b-a}$
期望：$\mathbb{E}[x]=\frac{a+b}{2}$
方差：$var[x]=\frac{(b-a)^2}{12}$

#### 伯努利分布

伯努利分布Bernoulli distribution是关于布尔变量$x\in\{0,1\}$的概率分布，其连续参数$\mu\in[0,1]$表示变量x=1的概率。
$P(x|\mu)=Bern(x|\mu)=\mu^x(1-\mu)^{1-x}$

#### 二项分布

二项分布binomial distribution用以描述N次独立的伯努利实验中有m次成功(即x=1)的概率，其中每次伯努利实验成功的概率为$\mu\in[0,1]$

#### 多项分布

在此基础上扩展二项分布则得到多项分布(multinomial distribution)，它描述了在N次独立实验中的$m_i$次$x_i=1$的概率。

#### 贝塔分布

贝塔分布Beta distribution是关于连续变量$\mu\in[0,1]$的概率分布，它由两个参数a>0和b>0确定，其概率密度函数如图所示。

#### 狄利克雷分布

狄利克雷分布Dirichlet distribution是关于一组d个连续变量$\mu\in[0,1]$的概率分布

#### 高斯分布

高斯分布Gaussian distribution亦称正态分布normal distribution是应用最为广泛的连续概率分布。

#### 共轭分布

#### KL散度

KL散度Kullback-Leibler divergence，亦称相对熵relative entropy或信息散度information divergence，可用于度量两个概率分布之间的差异。给定两个概率分布P和Q，二者之间的KL散度定义为
$KL(P||Q)=\int_{-\infty}^{\infty}p(x)\log\frac{p(x)}{q(x)}dx$

其中p(x)和q(x)分别为P和Q的概率密度函数。

KL散度满足非负性，即
$KL(P||Q)\ge0$

当且仅当P=Q时KL(P||Q)=0。但是，KL散度不满足对称性，即
$KL(P||Q)\ne KL(Q||P)$
因此，KL散度不是一个度量metric

若将KL散度的定义展开，可得
$KL(P||Q)=\int_{-\infty}^{\infty}p(x)\log p(x)dx-\int_{-\infty}^{\infty}q(x)\log q(x)dx=-H(P)+H(P,Q)$
其中H(P)为熵entropy，H(P,Q)为P和Q的交叉熵cross entropy。在信息论中，熵H(P)表示对来自P的随机变量进行编码所需的最小字节数，而交叉熵H(P,Q)则表示使用基于Q的编码对来自P的变量进行编码所需的字节数。因此，KL散度可认为是使用基于Q的编码对来自P的变量进行编码所需的“额外”字节数；显然，额外字节数必数非负，当且仅当P=Q时额外字节数为零。
